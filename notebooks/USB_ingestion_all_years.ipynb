{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SUSB_ingestion_all_years.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harperd17/energy_volatility_prediction/blob/main/notebooks/USB_ingestion_all_years.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M4Cc2F_DO7_"
      },
      "source": [
        "# Gather Data 2001 - 2018 from SUSB for back fill of electric accounts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfv_JvZ8XzUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0010acec-7816-4a11-cb22-6bc9afca29dd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import requests\n",
        "import xlrd\n",
        "import urllib\n",
        "from google.colab import drive\n",
        "\n",
        "!pip install us\n",
        "import us"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting us\n",
            "  Downloading us-2.0.2.tar.gz (14 kB)\n",
            "Collecting jellyfish==0.6.1\n",
            "  Downloading jellyfish-0.6.1.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 3.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: us, jellyfish\n",
            "  Building wheel for us (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for us: filename=us-2.0.2-py3-none-any.whl size=11942 sha256=6b0e1a8a5588805e936873021d6f6ae215ca627b525ce21cdefb1bcf4b65c6d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/6b/11/cda9ea2438f721330a35c9a2c8e34b4aedcd34c89af48a4d00\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.6.1-cp37-cp37m-linux_x86_64.whl size=72185 sha256=6cd4db17bc71b5bec0a88414995e811768df37bb91981834174971ce864e988c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/99/51/7de469e37cd1b3c763c24394e1ebf1baa2d79e094bf346cf80\n",
            "Successfully built us jellyfish\n",
            "Installing collected packages: jellyfish, us\n",
            "Successfully installed jellyfish-0.6.1 us-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icBlnRMJZ7rR"
      },
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7KFSFXLKioN"
      },
      "source": [
        "## Get the data for each year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znZeqpsD_9MP"
      },
      "source": [
        "# this contains the information needed to properly gather the data for each year - this is necessary because the data changes so much year to year\n",
        "metadata = {\n",
        "    '2001':{\n",
        "        'link': 'https://www2.census.gov/programs-surveys/susb/tables/2001/state_naicssector_2001.xls',\n",
        "        'header row':[7],\n",
        "        'columns':['STATE', 'CODE', 'DESCRIPTION', 'DATA TYPE', 'TOTAL', '0',\n",
        "                    '1-4', '5-9', '10-19', '<20', '20-99', '100-499', '<500', '500+']\n",
        "    },\n",
        "    '2002':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2002/state_naicssector_2002.xls',\n",
        "        'header row':[5,6],\n",
        "        'columns':['STATE','CODE','DESCRIPTION', 'DATA TYPE', 'TOTAL', '0',\n",
        "                    '1-4', '5-9', '10-19', '<20', '20-99', '100-499', '<500', '500+']\n",
        "    },\n",
        "    '2003':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2003/state_naicssector_2003.xls',\n",
        "        'header row':[7],\n",
        "        'columns':['STATE','CODE','DESCRIPTION', 'DATA TYPE', 'TOTAL', '0',\n",
        "                    '1-4', '5-9', '10-19', '<20', '20-99', '100-499', '<500', '500+']\n",
        "    },\n",
        "    '2004':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2004/state_naicssector_2004.xls',\n",
        "        'header row':[7],\n",
        "        'columns':['STATE','CODE','DESCRIPTION', 'DATA TYPE', 'TOTAL', '0',\n",
        "                    '1-4', '5-9', '10-19', '<20', '20-99', '100-499', '<500', '500+']\n",
        "    },\n",
        "    '2005':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2005/state_naicssector_2005.xls',\n",
        "        'header row':[7],\n",
        "        'columns':['STATE', 'CODE', 'DESCRIPTION', 'DATA TYPE', 'TOTAL', '0-4',\n",
        "                    '5-9', '10-19', '<20', '20-99', '100-499', '<500', '500+']\n",
        "    },\n",
        "    '2006':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2006/state_naicssector_2006.xls',\n",
        "        'header row':[7],\n",
        "        'columns':['STATE','CODE','DESCRIPTION', 'DATA TYPE', 'TOTAL',\n",
        "                    '0-4', '5-9', '10-19', '<20', '20-99', '100-499', '<500', '500+']\n",
        "    },\n",
        "    '2007':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2007/state_naicssector_2007.xls',\n",
        "        'header row':[5,6],\n",
        "        'columns':['STATE', 'CODE', 'DESCRIPTION', 'SIZE','FIRMS', 'ESTABLISHMENTS',\n",
        "                  'EMPLOYMENT', 'EMPLOYMENT RANGE FLAG','EMPLOYMENT NOISE FLAG', 'PAYROLL', 'PAYROLL NOISE FLAG', 'RECEIPTS','RECEIPTS NOISE FLAG'],\n",
        "        'pivot':True\n",
        "    },\n",
        "    '2008':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2008/state_naicssector_2008.xls',\n",
        "        'header row':[5],\n",
        "        'columns':['STATE CODE', 'STATE', 'CODE', 'DESCRIPTION', 'SIZE','FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT', 'RANGE FLAG',\n",
        "                  'NOISE FLAG', '-1000', 'NOISE FLAG.1'],\n",
        "        'pivot':True\n",
        "    },\n",
        "    '2009':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2009/state_naicssector_2009.xls',\n",
        "        'header row':[4],\n",
        "        'columns':['STATE CODE', 'STATE', 'CODE','DESCRIPTION', 'SIZE', 'FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT',\n",
        "                  'EMPLOYMENT RANGE FLAG', 'EMPLOYMENT NOISE FLAG', 'ANNUAL PAYROLL ($1,000)', 'ANNUAL PAYROLL NOISE FLAG'],\n",
        "        'pivot':True\n",
        "    },\n",
        "    '2010':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2010/state_naicssector_2010.xls',\n",
        "        'header row':[4],\n",
        "        'columns':['STATE CODE', 'STATE', 'CODE', 'DESCRIPTION', 'SIZE','FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT',\n",
        "                'EMPLOYMENT RANGE FLAG', 'EMPLOYMENT NOISE FLAG','ANNUAL PAYROLL ($1,000)', 'ANNUAL PAYROLL NOISE FLAG'],\n",
        "        'pivot':True\n",
        "    },\n",
        "    '2011':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2011/state_naicssector_2011.xls',\n",
        "        'header row':[4],\n",
        "        'columns':['STATE CODE', 'STATE', 'CODE','DESCRIPTION', 'SIZE','FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT',\n",
        "                  'EMPLOYMENT RANGE FLAG', 'EMPLOYMENT NOISE FLAG','ANNUAL PAYROLL ($1,000)', 'ANNUAL PAYROLL NOISE FLAG'],\n",
        "       'pivot':True\n",
        "    },\n",
        "    '2012':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2012/state_naicssector_2012.xls',\n",
        "        'header row':[5],\n",
        "        'columns':['STATE CODE', 'STATE', 'CODE','DESCRIPTION', 'SIZE', 'FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT',\n",
        "                  'EMPLOYMENT RANGE FLAG', 'EMPLOYMENT NOISE FLAG','ANNUAL PAYROLL ($1,000)', 'ANNUAL PAYROLL NOISE FLAG', 'RECEIPTS      ($1,000)', 'RECEIPTS NOISE FLAG'],\n",
        "        'pivot':True\n",
        "    },\n",
        "    '2013':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2013/state_naicssector_2013.xlsx',\n",
        "        'header row':[5],\n",
        "        'columns':['STATE CODE', 'STATE', 'CODE','DESCRIPTION', 'SIZE', 'FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT',\n",
        "                  'EMPLOYMENT RANGE FLAG', 'EMPLOYMENT NOISE FLAG', 'ANNUAL PAYROLL ($1,000)', 'ANNUAL PAYROLL NOISE FLAG'],\n",
        "        'pivot':True\n",
        "    },\n",
        "    '2014':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2014/state_naicssector_2014.xlsx',\n",
        "        'header row':[5],\n",
        "        'columns':['STATE CODE', 'STATE', 'CODE','DESCRIPTION', 'SIZE','FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT',\n",
        "                'EMPLOYMENT RANGE FLAG', 'EMPLOYMENT NOISE FLAG','ANNUAL PAYROLL ($1,000)', 'ANNUAL PAYROLL NOISE FLAG'],\n",
        "        'pivot':True\n",
        "    },\n",
        "    '2015':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2015/state_naicssector_2015.xlsx',\n",
        "        'header row':[5],\n",
        "        'columns':['STATE CODE', 'STATE', 'CODE','DESCRIPTION', 'SIZE','FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT',\n",
        "                  'EMPLOYMENT RANGE FLAG', 'EMPLOYMENT NOISE FLAG','ANNUAL PAYROLL ($1,000)', 'ANNUAL PAYROLL NOISE FLAG'],\n",
        "        'pivot':True\n",
        "    },\n",
        "    '2016':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2016/state_naicssector_2016.xlsx',\n",
        "        'header row':[6],\n",
        "        'columns':['STATE CODE', 'STATE', 'CODE','DESCRIPTION', 'SIZE','FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT',\n",
        "                  'EMPLOYMENT RANGE FLAG', 'EMPLOYMENT NOISE FLAG','ANNUAL PAYROLL ($1,000)', 'ANNUAL PAYROLL NOISE FLAG'],\n",
        "        'pivot':True\n",
        "    },\n",
        "    '2017':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2017/us_state_6digitnaics_2017.xlsx',\n",
        "        'header row':[2],\n",
        "        'columns':['STATE CODE', 'STATE', 'CODE', 'DESCRIPTION','SIZE', 'FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT','Employment\\nRange Flag', 'Employment Noise Flag',\n",
        "                   'Annual Payroll\\n($1,000)', 'Annual Payroll Noise Flag','Receipts\\n($1,000)', 'Receipts\\nNoise Flag'],\n",
        "        'pivot':True\n",
        "    },\n",
        "    '2018':{\n",
        "        'link':'https://www2.census.gov/programs-surveys/susb/tables/2018/us_state_6digitnaics_2018.xlsx',\n",
        "        'header row':[2],\n",
        "        'columns':['STATE CODE', 'STATE', 'CODE', 'DESCRIPTION', 'SIZE', 'FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT',\n",
        "                  'Employment Noise Flag', 'Annual Payroll\\n($1,000)','Annual Payroll Noise Flag'],\n",
        "        'pivot':True\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klCe77AsO0sj"
      },
      "source": [
        "# go through each year and gather the data and append the df for each year to list\n",
        "all_dfs_raw = []\n",
        "dfs_to_keep_2001_2006 = []\n",
        "dfs_to_keep_2007_2018 = []\n",
        "for year in metadata:\n",
        "  print(year)\n",
        "  year_info = metadata[year]\n",
        "  df = pd.read_excel(year_info['link'],header=year_info['header row'])\n",
        "  df.columns = year_info['columns']\n",
        "  df['YEAR'] = [int(year)]*df.shape[0]\n",
        "  all_dfs_raw.append(df)\n",
        "  if int(year) <= 2006:\n",
        "    dfs_to_keep_2001_2006.append(df[['YEAR','STATE','CODE','DESCRIPTION', 'DATA TYPE', 'TOTAL']].copy())\n",
        "  else:\n",
        "    dfs_to_keep_2007_2018.append(df[['YEAR','STATE', 'CODE','DESCRIPTION', 'SIZE','FIRMS', 'ESTABLISHMENTS', 'EMPLOYMENT']].copy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfy1Mdpx1stO"
      },
      "source": [
        "### First deal with the 2001-2006 data. I will pivot this data so that the different values (employment, firms, and establishments) are columns instead of taking up a whole row for each"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDnZbfk7Tmsk"
      },
      "source": [
        "# append all the 2001 through 2006 data together\n",
        "df_2001_2006 = pd.concat(dfs_to_keep_2001_2006).reset_index(drop=True)\n",
        "# append all the 2007 thorugh 2018 data together\n",
        "df_2007_2018 = pd.concat(dfs_to_keep_2007_2018).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkU6T_weT8xN"
      },
      "source": [
        "# I like the representation of having FIRMS, ESTABLISHMENTS, and EMPLOYMENT as their own columns so I will make the 2001 thorugh 2006 data match that representation\n",
        "df_2001_2006 = df_2001_2006.pivot(index=['STATE','DESCRIPTION','YEAR'], columns='DATA TYPE', values='TOTAL').reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr74DxZzXSLB"
      },
      "source": [
        "# we don't need all the variables\n",
        "df_2001_2006 = df_2001_2006[['STATE','DESCRIPTION','YEAR','Employment','Establishments','Firms']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-OdWgUW1rI4"
      },
      "source": [
        "df_2001_2006.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi157nP_53xm"
      },
      "source": [
        "df_2001_2006.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc7txePU2F3x"
      },
      "source": [
        "## Now deal with the 2007-2018 data. For these I only want to keep the \"total\" and get rid of the other breakdowns such as 0-4, 5-9, ...500+."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc7SVcoxXojN"
      },
      "source": [
        "# first I need to inspect the unique ways that establishment size have been written out over the years. It looks like I just need to search for 'total' being in the name (as lower case)\n",
        "df_2007_2018['SIZE'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh4oMOjyXiAp"
      },
      "source": [
        "# I will now make a new column that determines if 'total' is in the lower case string for each value in the SIZE column. Then I will subset based on that\n",
        "df_2007_2018['Total Size'] = df_2007_2018['SIZE'].str.lower().str.contains('total')\n",
        "# some of the years of data had a few blank rows below the header which results in 16 n/a values in this 'Total Size' column (they are n/a everywhere else too) so I will make those False too so they go away\n",
        "df_2007_2018['Total Size'] = df_2007_2018['Total Size'].fillna(False)\n",
        "# subset to where the row is for total and only keep a subset of the columns\n",
        "df_2007_2018 = df_2007_2018[df_2007_2018['Total Size']][['YEAR','STATE','DESCRIPTION','FIRMS','ESTABLISHMENTS','EMPLOYMENT']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KofPqkIN3EpY"
      },
      "source": [
        "# now the column names need to be consistent with the column names for the 2001-2006 data\n",
        "df_2007_2018.columns = ['YEAR','STATE','DESCRIPTION','Firms','Establishments','Employment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjE-cyG9Znjx"
      },
      "source": [
        "df_2007_2018.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0bALT2c57tk"
      },
      "source": [
        "df_2007_2018.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPzPX5hb3RE3"
      },
      "source": [
        "## Concatenate the dataframes to get a dataframe with years 2001-2018 of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQFTm67SZ6NH"
      },
      "source": [
        "# concatenate the two sets of years of data\n",
        "all_years_df = pd.concat([df_2001_2006, df_2007_2018]).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNcRSFzy3Xqj"
      },
      "source": [
        "# some of the data types are just objects and that's because the data has random letters in the numeric fields for some of the rows\n",
        "# I think these should be replaced with n/a's\n",
        "all_years_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXspf4YS3kGv"
      },
      "source": [
        "# this function will find all the non numeric values in a column and then replace them with n/a so that the field can become numeric\n",
        "def replace_non_numeric(df):\n",
        "  non_numeric = []\n",
        "  for col in df.columns:\n",
        "    for i in range(df.shape[0]):\n",
        "      try:\n",
        "        float(df[col].iloc[i]) \n",
        "      except:\n",
        "        non_numeric.append(df[col].iloc[i])\n",
        "  return df.replace(np.unique(non_numeric),np.nan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwC7tPIo3wCB"
      },
      "source": [
        "# the columns that should be numeric are Employment, Establishments, and Firms\n",
        "all_years_df[['Establishments','Firms','Employment']] = replace_non_numeric(all_years_df[['Establishments','Firms','Employment']].copy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmakOkaGurh0"
      },
      "source": [
        "all_years_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxTd4WFjFXJt"
      },
      "source": [
        "# Classification Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eQbdGp6EhQh"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_trf\") \n",
        "\n",
        "def lemmatize(description) -> list():\n",
        "\n",
        "    for token in doc:\n",
        "        token_lemma_list.append(token.lemma_.lower())\n",
        "\n",
        "    return token_lemma_list\n",
        "\n",
        "\n",
        "description_lemma_dict = dict()\n",
        "\n",
        "#Iterate through unique description, get lemma and lower description add to dict\n",
        "unique_descriptions = df_complete[\"DESCRIPTION\"].unique()\n",
        "\n",
        "\n",
        "for description in tqdm(unique_descriptions):\n",
        "    #Turns description in to an interable token list with attrs such as lemma\n",
        "    doc = nlp(description)\n",
        "    \n",
        "    #Keeps trak of current tokens already lemmatized and lower\n",
        "    token_lemma_list = list()\n",
        "    \n",
        "    #Iterate through each token in doc\n",
        "    for token in doc:\n",
        "        \n",
        "        token_lemma_list.append(token.lemma_.lower())\n",
        "    \n",
        "    description_lemma_dict.update({description:\" \".join(token_lemma_list)})\n",
        "\n",
        "all_years_df[\"Description_Lemma_Lower\"] = all_years_df[\"DESCRIPTION\"].apply(lambda description: description_lemma_dict[description])\n",
        "all_years_df[\"Description_Lower\"] = all_years_df[\"DESCRIPTION\"].str.lower()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZoon7uqFq-6"
      },
      "source": [
        "# now add the classifications to the dataframe\n",
        "def assign_classification(tokens,industry_words,commerical_words):\n",
        "    try:\n",
        "        for token in tokens.split(\" \"):\n",
        "\n",
        "            for ind_token in industry_words:\n",
        "\n",
        "                if ind_token in token:\n",
        "\n",
        "                    return \"IND\"\n",
        "\n",
        "            for com_token in commerical_words:\n",
        "\n",
        "                    if com_token in token:\n",
        "                        \n",
        "                        return \"COM\"\n",
        "        \n",
        "        return \"OTH\"\n",
        "\n",
        "    except:\n",
        "        return \"Not Found\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrszRtgiFt2F"
      },
      "source": [
        "# Words to classification description as IND\n",
        "industry_tokens = [\"mining\",\"mill\",\"manufacture\",\"industrial\",\"material\",\"chemical\",\"part\",\"unit\",\"machine\",\"manufacturing\"\n",
        "                    ,\"fuel\",\"water\",\"electric\",\"generate\",\"quarry\",\"industrial\",\"facil\",\"equipment\",\"metal\",\"freight\"\n",
        "                ]\n",
        "\n",
        "\n",
        "# Words to classification description as COM\n",
        "commerical_tokens = [\"service\",\"sale\",\"admin\",\"office\",\"wholesaler\",\"financ\"\n",
        "                    ,\"store\",\"clothing\",\"support\",\"salon\",\"broadcast\",\"intermediat\",\"agency\",\"dealer\"\n",
        "                    ,\"appraiser\",\"telecommunication\",\"sell\",\"bank\",\"repair\",\"school\",\"commercial\",\"merchandise\", \"professional\"\n",
        "                    ,\"advertis\",\"publisher\",\"agency\",\"contractor\",\"research\",\"real\",\"estate\",\"social\",\"markets\",\"information\",\"insurance\",\"trade\"\n",
        "                    ,\"hospitals\",\"rental\",\"construction\"]\n",
        "\n",
        "\n",
        "\n",
        "all_years_df[\"Classification_Lower\"] = (all_years_df[\"Description_Lower\"]\n",
        "                                 .apply(lambda description: assign_classification(description,industry_tokens,commerical_tokens))\n",
        "                                 \n",
        "                                 )\n",
        "\n",
        "all_years_df[\"Classification_Lemma_Lower\"] = (all_years_df[\"Description_Lemma_Lower\"]\n",
        "                                 .apply(lambda description: assign_classification(description,industry_tokens,commerical_tokens))\n",
        "\n",
        "                                    )\n",
        "\n",
        "\n",
        "\n",
        "_ = (all_years_df[[\"Classification_Lower\",\"Classification_Lemma_Lower\",\"STATE\"]].groupby('Classification_Lower').count()\n",
        ".rename(columns={\"STATE\":\"Count\"})\n",
        ".sort_values(\"Count\",ascending=False)\n",
        ").plot(kind=\"bar\",title=\"Classification Count - Lower\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK4rV-vxFlxC"
      },
      "source": [
        "\n",
        "# Most frequently used words in OTH description\n",
        "\n",
        "description_list = all_years_df.query('Classification_Lemma_Lower == \"OTH\"')[\"Description_Lemma_Lower\"].to_list()\n",
        "\n",
        "count_dictionary = dict()\n",
        "\n",
        "\n",
        "for description in description_list:\n",
        "\n",
        "    for token in description.split(\" \"):\n",
        "\n",
        "        if token.strip() in count_dictionary.keys():\n",
        "\n",
        "            count_dictionary[token] += 1\n",
        "\n",
        "        else:\n",
        "\n",
        "            count_dictionary[token] = 1\n",
        "\n",
        "\n",
        "pd.DataFrame([count_dictionary]).T.rename(columns={0:\"Count\"}).sort_values(\"Count\",ascending=False).head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwp52LtF5hA8"
      },
      "source": [
        "### Add state abbreviations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHxYyPqI5lnQ"
      },
      "source": [
        "state_abbrev = []\n",
        "for s in all_years_df['STATE']:\n",
        "  if s != 'United States':\n",
        "    state_object = us.states.lookup(s)\n",
        "    state_abbrev.append(state_object.abbr)\n",
        "  else:\n",
        "    state_abbrev.append(np.nan)\n",
        "all_years_df['STATE'] = state_abbrev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiP9Pv4fAi2I"
      },
      "source": [
        "all_years_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGuj54K5Afuu"
      },
      "source": [
        "# there are a lot of places where STATE is null because the value was total for the whole United STates so these should be removed\n",
        "all_years_df = all_years_df[~all_years_df['STATE'].isnull()].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aemC1Hd-_dv"
      },
      "source": [
        "all_years_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocYFZNQLZy_F"
      },
      "source": [
        "# now save this dataframe\n",
        "all_years_df.to_csv('/content/drive/Shareddrives/Data606_Energy/data/fill_ready/SUSB_data_all_2001_2018.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6kPet4YhGDz"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.bar(df,x=\"Classification\",y=\"count\",text=\"tokens\",title=\"Tokens Search for to Determine Classification\")\n",
        "\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=2000,\n",
        "    height=1000,\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5EYpLR0h6Nk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}